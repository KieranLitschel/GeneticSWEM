{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GEA_8_8_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDV0-KftQyYb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9781dc9e-58ec-4ff7-f108-b57cb62894de"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import multiprocessing\n",
        "from tqdm import tqdm\n",
        "import sklearn\n",
        "import itertools\n",
        "import pickle\n",
        "\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print('GPU device not found')\n",
        "else:\n",
        "    print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xK_yubJCjX1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "VALIDATION_PERCENT_SPLIT = 0.1\n",
        "TRAIN_SET_FRAC = 1 # fraction of training and validatipn set to use\n",
        "REBUILD_DATASET = False # whether to download pre-processed features, or pre-process from scratch (takes approx 20 mins extra if rebuilding from scratch)\n",
        "LOAD_TEST_SET = True # whether to load test set into memory\n",
        "BASES = [\"G\",\"A\",\"T\",\"C\",\"N\"]\n",
        "N = 8 # if you change this set rebuild dataset to True\n",
        "VOCAB = np.unique([''.join(permutation) for combination in itertools.combinations_with_replacement(BASES, r=N) for permutation in itertools.permutations(combination)])\n",
        "OVERSAMPLING_THRESHOLD = -float(\"inf\")\n",
        "SCALED_OVERSAMPLING_THRESHOLD = OVERSAMPLING_THRESHOLD*TRAIN_SET_FRAC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4_VCHQAQ5aV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "8b99c5e8-fe6e-4624-f25c-56d7cdc4b257"
      },
      "source": [
        "# download the labels\n",
        "\n",
        "TRAIN_LABELS_URL = \"https://drivendata-prod.s3.amazonaws.com/data/63/public/train_labels.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIARVBOBDCY3EFSLNZR%2F20200903%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200903T110025Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=25b182218a98f662183275df8ae5ddfa7cd3d6a15a0760fba4f9db8a43bd7aa8\"\n",
        "train_labels_file_path = tf.keras.utils.get_file(\"train_labels.csv\", TRAIN_LABELS_URL)\n",
        "train_labels_df = pd.read_csv(train_labels_file_path, index_col=\"sequence_id\")\n",
        "\n",
        "# preprocess the features\n",
        "\n",
        "encoder = tfds.features.text.SubwordTextEncoder(vocab_list=VOCAB)\n",
        "VOCAB_SIZE=len(VOCAB)\n",
        "\n",
        "if REBUILD_DATASET:\n",
        "    TRAIN_DATA_URL = \"https://drivendata-prod.s3.amazonaws.com/data/63/public/train_values.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIARVBOBDCY3EFSLNZR%2F20200829%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200829T110926Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=097b0ed7c35d539666bdc3491076b140b8797bf32349f41d83737225de73b346\"\n",
        "    TEST_DATA_URL = \"https://drivendata-prod.s3.amazonaws.com/data/63/public/test_values.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIARVBOBDCY3EFSLNZR%2F20200829%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200829T110926Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=b9a06609a313b5519114f75c5106ed945f2fa31421872a85241ca802b031ec07\"\n",
        "\n",
        "    train_features_file_path = tf.keras.utils.get_file(\"train_features.csv\", TRAIN_DATA_URL)\n",
        "    test_features_file_path = tf.keras.utils.get_file(\"test_features.csv\", TEST_DATA_URL)\n",
        "\n",
        "    train_features_df = pd.read_csv(train_features_file_path, index_col=\"sequence_id\")\n",
        "    if LOAD_TEST_SET:\n",
        "        test_features_df = pd.read_csv(test_features_file_path, index_col=\"sequence_id\")\n",
        "\n",
        "    # encode sequence\n",
        "    def encode_sequence(features_file_path, encoder):\n",
        "        features_df = pd.read_csv(features_file_path, index_col=\"sequence_id\")\n",
        "        # if the len(sequence)%N != 0, we discard of the extra characters, we also encode each sequence of N characters seperately as SubwordTextEncoder computes overlapping encodings\n",
        "        features_df[\"sequence\"] = [[encoder.encode(sequence[i:i+N])[0] for i in range(0,len(sequence)-(N-1),N)] for sequence in tqdm(features_df[\"sequence\"])]\n",
        "        return features_df\n",
        "\n",
        "    train_features_df = encode_sequence(train_features_file_path, encoder)\n",
        "    if LOAD_TEST_SET:\n",
        "        test_features_df = encode_sequence(test_features_file_path, encoder)\n",
        "\n",
        "    # convert one-hot features to int\n",
        "    column_type_dict = {\"sequence\":object}\n",
        "    for column in train_features_df.columns[1:]:\n",
        "        column_type_dict[column] = np.int16\n",
        "    train_features_df = train_features_df.astype(column_type_dict)\n",
        "    train_features_df.to_pickle(\"base_{}_encoded_train_features_df.pickle\".format(N))\n",
        "    if LOAD_TEST_SET:\n",
        "        test_features_df = test_features_df.astype(column_type_dict)\n",
        "        test_features_df.to_pickle(\"base_{}_encoded_test_features_df.pickle\".format(N))\n",
        "else:\n",
        "    !gdown --id 1FwnBsK8EVp4U5U9zCsU505M-k2gcqyj-\n",
        "    !tar zxvf base_8_encoded.tar.gz -C .\n",
        "    train_features_df = pd.read_pickle(\"base_encoded/base_{}_encoded_train_features_df.pickle\".format(N))\n",
        "    if LOAD_TEST_SET:\n",
        "        test_features_df = pd.read_pickle(\"base_encoded/base_{}_encoded_test_features_df.pickle\".format(N))\n",
        "\n",
        "NUM_LABELS = len(train_labels_df.columns)\n",
        "\n",
        "# determine class weights\n",
        "\n",
        "train_labels_single_column = train_labels_df.dot(range(len(train_labels_df.columns))).astype(np.int16).values # converts one hot representation to single column\n",
        "labels_in_training_set = np.unique(train_labels_single_column)\n",
        "class_weights_list = sklearn.utils.class_weight.compute_class_weight('balanced',\n",
        "                                                 labels_in_training_set,\n",
        "                                                 train_labels_single_column)\n",
        "class_weights = {class_no: weight for class_no, weight in zip(labels_in_training_set, class_weights_list)}\n",
        "\n",
        "# build validation set\n",
        "indexes = list(train_features_df.index)\n",
        "np.random.seed(26082020)\n",
        "np.random.shuffle(indexes)\n",
        "# ensure that the number of labels for each class in each subset are balanced\n",
        "indexes_by_class = {key:[] for key in range(NUM_LABELS)}\n",
        "for index in indexes:\n",
        "    indexes_by_class[np.argmax(train_labels_df.loc[index].values)].append(index)\n",
        "validation_indexes = []\n",
        "train_indexes = []\n",
        "for class_no in range(NUM_LABELS):\n",
        "    number_of_samples = len(indexes_by_class[class_no])\n",
        "    # if we don't want the whole training set, then at minimum we will take 2 samples (one for each subset), as long as there are at least 2\n",
        "    number_of_samples_to_take = max(int(number_of_samples*TRAIN_SET_FRAC),min(number_of_samples,2))\n",
        "    validation_samples = int(number_of_samples_to_take*VALIDATION_PERCENT_SPLIT)\n",
        "    # ensure that there is at least 1 sample for each class in the validation set, unless there is 1 one in the training set, in which case we allocate it to the new training set\n",
        "    if validation_samples == 0 and number_of_samples_to_take!=1:\n",
        "        validation_samples = 1\n",
        "    for sample_no, sample in enumerate(indexes_by_class[class_no][:number_of_samples_to_take]):\n",
        "        if sample_no < validation_samples:\n",
        "            validation_indexes.append(sample)\n",
        "        else:\n",
        "            train_indexes.append(sample)\n",
        "    # oversample if there are fewer training samples for the class than the thresold\n",
        "    class_train_indexes = indexes_by_class[class_no][:number_of_samples_to_take][validation_samples:]\n",
        "    if len(class_train_indexes) < SCALED_OVERSAMPLING_THRESHOLD:\n",
        "        # the minus one is because we have already added the indexes to train_indexes once in the previous loop\n",
        "        oversampled_class_train_indexes = class_train_indexes * (int(SCALED_OVERSAMPLING_THRESHOLD/len(class_train_indexes))-1) + class_train_indexes[:SCALED_OVERSAMPLING_THRESHOLD%len(class_train_indexes)]\n",
        "        for sample in oversampled_class_train_indexes:\n",
        "            train_indexes.append(sample)\n",
        "\n",
        "# shuffle again so indexes are not ordered by class\n",
        "np.random.seed(27082020)\n",
        "np.random.shuffle(validation_indexes)\n",
        "np.random.seed(28082020)\n",
        "np.random.shuffle(train_indexes)\n",
        "# set up their dataframes\n",
        "validation_features_df = train_features_df.loc[validation_indexes]\n",
        "validation_labels_df = train_labels_df.loc[validation_indexes]\n",
        "train_features_df = train_features_df.loc[train_indexes]\n",
        "train_labels_df = train_labels_df.loc[train_indexes]\n",
        "\n",
        "# the only way to get uneven lists into tf.data.Dataset is using ragged tensors, but padded\n",
        "# batch does not support ragged tensors, and we can not pad before training as we will run out\n",
        "# of memory, so we just convert the lists to binary and then convert them back to ints in the\n",
        "# pipeline\n",
        "\n",
        "train_features_df[\"sequence\"] = [pickle.dumps(sequence) for sequence in train_features_df[\"sequence\"]]\n",
        "validation_features_df[\"sequence\"] = [pickle.dumps(sequence) for sequence in validation_features_df[\"sequence\"]]\n",
        "if LOAD_TEST_SET:\n",
        "    test_features_df[\"sequence\"] = [pickle.dumps(sequence) for sequence in test_features_df[\"sequence\"]]\n",
        "\n",
        "# build datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(({\"sequence\":train_features_df[\"sequence\"].values,\"other_features\":train_features_df.drop(columns=\"sequence\").values},train_labels_df.values))\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices(({\"sequence\":validation_features_df[\"sequence\"].values,\"other_features\":validation_features_df.drop(columns=\"sequence\").values},validation_labels_df.values))\n",
        "if LOAD_TEST_SET:\n",
        "    test_dataset = tf.data.Dataset.from_tensor_slices({\"sequence\":test_features_df[\"sequence\"].values,\"other_features\":test_features_df.drop(columns=\"sequence\").values})\n",
        "\n",
        "# save unshufled train dataset for evaluation\n",
        "unshuffled_train_dataset = tf.data.Dataset.from_tensor_slices(({\"sequence\":train_features_df[\"sequence\"].values,\"other_features\":train_features_df.drop(columns=\"sequence\").values},train_labels_df.values))\n",
        "\n",
        "# shuffle train\n",
        "train_dataset = train_dataset.shuffle(BATCH_SIZE*2)\n",
        "\n",
        "# convert binary to ints\n",
        "\n",
        "def bin_to_int(sequence_tensor):\n",
        "    return [pickle.loads(sequence_tensor.numpy())]\n",
        "\n",
        "def tf_bin_to_int(*tensors):\n",
        "    if len(tensors) == 2:\n",
        "        features_dict, labels_tensor = tensors\n",
        "    else:\n",
        "        features_dict = tensors[0]\n",
        "    sequence_tensor = features_dict[\"sequence\"]\n",
        "    sequence_tensor = tf.py_function(bin_to_int, inp=[sequence_tensor], Tout=tf.int32)\n",
        "    sequence_tensor.set_shape([None])\n",
        "    features_dict[\"sequence\"] = sequence_tensor\n",
        "    if len(tensors) == 2:\n",
        "        tensors = (features_dict, labels_tensor)\n",
        "    else:\n",
        "        tensors = features_dict\n",
        "    return tensors\n",
        "\n",
        "train_dataset = train_dataset.map(tf_bin_to_int,\n",
        "                                  num_parallel_calls=multiprocessing.cpu_count())\n",
        "unshuffled_train_dataset = unshuffled_train_dataset.map(tf_bin_to_int,\n",
        "                                  num_parallel_calls=multiprocessing.cpu_count())\n",
        "validation_dataset = validation_dataset.map(tf_bin_to_int,\n",
        "                                  num_parallel_calls=multiprocessing.cpu_count())\n",
        "if LOAD_TEST_SET:\n",
        "    test_dataset = test_dataset.map(tf_bin_to_int,\n",
        "                                  num_parallel_calls=multiprocessing.cpu_count())\n",
        "\n",
        "# pre fetch\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "unshuffled_train_dataset = unshuffled_train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "validation_dataset = validation_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "if LOAD_TEST_SET:\n",
        "    test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# batch datasets\n",
        "train_dataset = train_dataset.padded_batch(BATCH_SIZE)\n",
        "unshuffled_train_dataset = unshuffled_train_dataset.padded_batch(BATCH_SIZE)\n",
        "validation_dataset = validation_dataset.padded_batch(BATCH_SIZE)\n",
        "if LOAD_TEST_SET:\n",
        "    test_dataset = test_dataset.padded_batch(BATCH_SIZE)\n",
        "\n",
        "# pre fetch\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "unshuffled_train_dataset = unshuffled_train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "validation_dataset = validation_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "if LOAD_TEST_SET:\n",
        "    test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://drivendata-prod.s3.amazonaws.com/data/63/public/train_labels.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIARVBOBDCY3EFSLNZR%2F20200903%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200903T110025Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=25b182218a98f662183275df8ae5ddfa7cd3d6a15a0760fba4f9db8a43bd7aa8\n",
            "331612160/331607292 [==============================] - 8s 0us/step\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1FwnBsK8EVp4U5U9zCsU505M-k2gcqyj-\n",
            "To: /content/base_8_encoded.tar.gz\n",
            "92.6MB [00:00, 95.8MB/s]\n",
            "base_encoded/\n",
            "base_encoded/base_8_encoded_test_features_df.pickle\n",
            "base_encoded/base_8_encoded_train_features_df.pickle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y59Ij_85WrEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _top_10_accuracy_scorer(y_true, y_pred):\n",
        "    # get the indices for top 10 predictions for each row; these are the last ten in each row\n",
        "    # Note: We use argpartition, which is O(n), vs argsort, which uses the quicksort algorithm \n",
        "    # by default and is O(n^2) in the worst case. We can do this because we only need the top ten\n",
        "    # partitioned, not in sorted order.\n",
        "    # Documentation: https://numpy.org/doc/1.18/reference/generated/numpy.argpartition.html\n",
        "    top10_idx = np.argpartition(y_pred, -10, axis=1)[:, -10:]\n",
        "    \n",
        "    # set top 10 indexes to 1's, the rest 0\n",
        "    top_10_identity = np.zeros(y_pred.shape)\n",
        "    for sample_no, top_10 in enumerate(top10_idx):\n",
        "        top_10_identity[sample_no][top_10] = 1\n",
        "\n",
        "    # determine the number correct\n",
        "    top_10_correct = np.sum(top_10_identity*y_true,axis=1)\n",
        "    \n",
        "    # take the mean\n",
        "    top_10_accuracy = np.mean(top_10_correct)\n",
        " \n",
        "    return top_10_accuracy\n",
        "\n",
        "def top10_accuracy_scorer(model, dataset, ground_truths):\n",
        "    \"\"\"A custom scorer that evaluates a model on whether the correct label is in \n",
        "    the top 10 most probable predictions.\n",
        "\n",
        "    Args:\n",
        "        model (tf.model): The tf model that should be evaluated.\n",
        "        dataset (tf.data.Dataset): The validation data.\n",
        "        ground_truths (numpy array): The one-hot-encoded ground truth labels.\n",
        "\n",
        "    Returns:\n",
        "        float: Accuracy of the model as defined by the proportion of predictions\n",
        "               in which the correct label was in the top 10. Higher is better.\n",
        "    \"\"\"\n",
        "    # predict the probabilities across all possible labels for rows in our training set\n",
        "    probas = model.predict(dataset)\n",
        "    \n",
        "    return _top_10_accuracy_scorer(ground_truths, probas)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC7XDilNS0Gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.load_model('GE_8_8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Aj1ws7O_JIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_probs = model.predict(validation_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5QCgfj_d97H",
        "colab_type": "text"
      },
      "source": [
        "Build a dataframe containing examples our model misclassifies in the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r9l287cNUQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true = np.argmax(validation_labels_df.values,axis=1)\n",
        "top10_idx = np.argpartition(y_pred_probs, -10, axis=1)[:, -10:]\n",
        "y_pred_label = np.argmax(y_pred_probs,axis=1)\n",
        "top_10_wrong_mask = [y_true[i] not in top10_idx[i] for i in range(len(y_true))]\n",
        "wrong_indexes = validation_labels_df.index.values[top_10_wrong_mask]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p2oXd4MNzX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrong_df = validation_features_df.loc[wrong_indexes]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agGVnRQFeZuW",
        "colab_type": "text"
      },
      "source": [
        "776 examples are misclassified"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi26DA8_YimV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65131b24-bc47-43a7-cefb-c158fb6b78b8"
      },
      "source": [
        "wrong_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(776, 40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kThc6lXfeeTc",
        "colab_type": "text"
      },
      "source": [
        "Dump the binary sequences back to numpy arrays and find the unique words (where a word is an 8 long sequence using only the characters G, A, T, C, and N) in the training, validation, and test set, and the set of examples we are misclassifying"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIe5BEKxOvJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrong_sequence = [pickle.loads(sequence) for sequence in wrong_df[\"sequence\"].values]\n",
        "validation_sequence = [pickle.loads(sequence) for sequence in validation_features_df[\"sequence\"].values]\n",
        "train_sequence = [pickle.loads(sequence) for sequence in train_features_df[\"sequence\"].values]\n",
        "test_sequence = [pickle.loads(sequence) for sequence in test_features_df[\"sequence\"].values]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G8uJbAHQdXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrong_unique_words = np.unique([word for sequence in wrong_sequence for word in sequence])\n",
        "validation_unique_words = np.unique([word for sequence in validation_sequence for word in sequence])\n",
        "train_unique_words = np.unique([word for sequence in train_sequence for word in sequence])\n",
        "test_unique_words = np.unique([word for sequence in test_sequence for word in sequence])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu2nnymMei24",
        "colab_type": "text"
      },
      "source": [
        "429 words that do not occur in the training set occur in the set of examples we are misclassifying."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnH-bON9Q0vO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dfe570ac-223e-4a07-9ed9-04a852090c89"
      },
      "source": [
        "words_not_in_train = set(wrong_unique_words).difference(train_unique_words)\n",
        "len(words_not_in_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "429"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAcEkl4KZxCQ",
        "colab_type": "text"
      },
      "source": [
        "10.8% of examples we're getting wrong contain an unknown word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMPNJHkHYlXg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f42fbd3-34dd-4483-abcf-445242c1bdc6"
      },
      "source": [
        "print(sum(1 for sequence in wrong_sequence if any(word in words_not_in_train for word in sequence))/len(wrong_sequence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.10824742268041238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRecG3s-fWmc",
        "colab_type": "text"
      },
      "source": [
        "In contrast, only 4.9% of examples in the validation set contain an unknown word, so unknown words may be confusing our classifier. As currently the embedding for words unseen in the training set will just be the default initialisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_8_OQvNRW47",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e87e03a-c1da-49a6-cc7c-58f27f994e99"
      },
      "source": [
        "validation_words_not_in_train = set(validation_unique_words).difference(train_unique_words)\n",
        "len(validation_words_not_in_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1357"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_LjVtNjZOkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1defc8b2-7367-42e5-a937-a6db7eaf9664"
      },
      "source": [
        "print(sum(1 for sequence in validation_sequence if any(word in validation_words_not_in_train for word in sequence))/len(validation_sequence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.04973562458691342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG5XWVLCf5U6",
        "colab_type": "text"
      },
      "source": [
        "Further 5000 unknown words in the test set, so this might be why we are performing worse on the test set compared to the validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM31Jb6dStak",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "477cfd39-740a-4344-81fb-eaaccaab0039"
      },
      "source": [
        "len(set(test_unique_words).difference(train_unique_words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5193"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l94WMjcPgT2n",
        "colab_type": "text"
      },
      "source": [
        "There are only 83000 unique words in the training set, so the number of unknown words is significant."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmU8hwucRbs3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "091c392d-9fed-4c20-b823-afd213a490bf"
      },
      "source": [
        "len(train_unique_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83244"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4TcXAWlgcHg",
        "colab_type": "text"
      },
      "source": [
        "We count the frequency of the words across all sequences for each subset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyP3wnS8UDxV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8ccd1c50-be3b-4326-b141-bcf1ad7be066"
      },
      "source": [
        "pd.Series([word for sequence in wrong_sequence for word in sequence]).value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "144657    125\n",
              "7610      115\n",
              "381447    115\n",
              "93383     107\n",
              "33925     106\n",
              "         ... \n",
              "98396       1\n",
              "100445      1\n",
              "356546      1\n",
              "334031      1\n",
              "184615      1\n",
              "Length: 58654, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6GbpZ5nUPsk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "57c815e2-9294-49f6-a1fc-c716095e363f"
      },
      "source": [
        "pd.Series([word for sequence in validation_sequence for word in sequence]).value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1522      1158\n",
              "144657    1049\n",
              "7610       977\n",
              "33925      954\n",
              "195288     904\n",
              "          ... \n",
              "97659        1\n",
              "286707       1\n",
              "261894       1\n",
              "231177       1\n",
              "276579       1\n",
              "Length: 67617, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ_McfFLUTQ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "7b41d493-ac52-4361-cce2-f5b17d7786d1"
      },
      "source": [
        "train_value_counts = pd.Series([word for sequence in train_sequence for word in sequence]).value_counts()\n",
        "train_value_counts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1522      10515\n",
              "144657     9775\n",
              "7610       9467\n",
              "33925      8827\n",
              "34637      8427\n",
              "          ...  \n",
              "238657        1\n",
              "192672        1\n",
              "238658        1\n",
              "205906        1\n",
              "175917        1\n",
              "Length: 83244, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VhbW2HeUY_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "3851431a-5913-48fe-d2a6-02a77d24f578"
      },
      "source": [
        "pd.Series([word for sequence in test_sequence for word in sequence]).value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7610      3518\n",
              "33925     3110\n",
              "381447    2995\n",
              "1522      2734\n",
              "144657    2721\n",
              "          ... \n",
              "95543        1\n",
              "79167        1\n",
              "353126       1\n",
              "117741       1\n",
              "164803       1\n",
              "Length: 72331, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ_rdPzzgtAK",
        "colab_type": "text"
      },
      "source": [
        "The value counts of the value counts tells us how frequent each word frequency is. We see that 17077 words occur three or less times in the training set. Such low frequencies means that it is hard to learn a good embedding for them. So we remove them from the vocabulary in model GE_8_9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bpXJU_UVFzE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "fbadaf28-3e81-4897-bd1e-decf0901fb3e"
      },
      "source": [
        "pd.Series([word for sequence in train_sequence for word in sequence]).value_counts().value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1       15481\n",
              "2        1236\n",
              "3         360\n",
              "133       214\n",
              "142       196\n",
              "        ...  \n",
              "4942        1\n",
              "1497        1\n",
              "3672        1\n",
              "3736        1\n",
              "7778        1\n",
              "Length: 3761, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wv5LihSAVMxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = [encoder.decode([word]) for word in train_value_counts.index.values if train_value_counts.loc[word]>3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkrDD-4RXBZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}